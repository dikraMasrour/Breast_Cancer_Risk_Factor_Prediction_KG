{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1F9cAEOi46tF6vbzLKuQdjoptFIRxDEuc",
      "authorship_tag": "ABX9TyPtvj6ZlcjZR5N0YeCA5ppm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dikraMasrour/Breast_Cancer_Risk_Factor_Prediction_KG/blob/main/untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torchkge"
      ],
      "metadata": {
        "id": "g6w4CDVys4DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mounting drive"
      ],
      "metadata": {
        "id": "zCrxoym3Yrui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pq-xsYR32_Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "9SzHugFQYqZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPGZsp_8smjJ"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "from torch.optim import Adam\n",
        "from torchkge.models import TransEModel\n",
        "from torchkge.sampling import BernoulliNegativeSampler\n",
        "from torchkge.utils import MarginLoss, DataLoader\n",
        "from torchkge.utils.datasets import load_fb15k\n",
        "from tqdm.autonotebook import tqdm\n",
        "import torch\n",
        "from torchkge.evaluation import LinkPredictionEvaluator\n",
        "import numpy as np\n",
        "from os.path import join\n",
        "from os import makedirs, remove\n",
        "from os.path import exists\n",
        "from pandas import concat, DataFrame, merge, read_csv\n",
        "from urllib.request import urlretrieve\n",
        "from torchkge.data_structures import KnowledgeGraph\n",
        "# from torchkge.utils import get_data_home, safe_extract\n",
        "from torchkge.utils import get_data_home\n",
        "from torchkge.utils.operations import extend_dicts\n",
        "from pandas import concat, DataFrame, merge, read_csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up cuda is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "DwNulX_2twgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataPath = \"/content/drive/MyDrive/Colab Notebooks/KG_breast_cancer/Copie de all_data_triples_can.csv\"\n",
        "df = read_csv(dataPath, compression='gzip')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "furUAEJm8qYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(df_):\n",
        "    train_df = df_.groupby(['from', 'to']).sample(frac = 0.8)\n",
        "    test_val = df_[~df_.index.isin(train_df.index)]\n",
        "    test_df = df_.sample(frac = 0.5)\n",
        "    val_df = test_val[~test_val.index.isin(test_df.index)]\n",
        "    print(train_df.shape, test_df.shape, val_df.shape)\n",
        "    return train_df, test_df, val_df\n"
      ],
      "metadata": {
        "id": "OTXsmkxZ5_pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.rename(columns={'SUBJECT_CUI': 'from'})\n",
        "df2 = df1.rename(columns={'OBJECT_CUI': 'to'})\n",
        "df3 = df2.rename(columns={'PREDICATE': 'rel'})"
      ],
      "metadata": {
        "id": "uK1Q89Ki9wAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.head()"
      ],
      "metadata": {
        "id": "J7d5IWls-EcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df3[\"ORIGIN_ID\"]\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "qTm40seH-Pgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df, test_df, val_df = split(df3)"
      ],
      "metadata": {
        "id": "GIFeWSor9cWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  In general\n",
        "def load_biodata(data_home=None):\n",
        "    \"\"\"Load FB13 dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_home: str, optional\n",
        "        Path to the `torchkge_data` directory (containing data folders). If\n",
        "        files are not present on disk in this directory, they are downloaded\n",
        "        and then placed in the right place.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    kg_train: torchkge.data_structures.KnowledgeGraph\n",
        "    kg_val: torchkge.data_structures.KnowledgeGraph\n",
        "    kg_test: torchkge.data_structures.KnowledgeGraph\n",
        "\n",
        "    \"\"\"\n",
        "    data_path = data_home + '/biodata'\n",
        "\n",
        "    df1 = read_csv(data_path + '/train.csv')\n",
        "    df2 = read_csv(data_path + '/valid.csv')\n",
        "    df3 = read_csv(data_path + '/test.csv')\n",
        "    df = concat([df1, df2, df3])\n",
        "    kg = KnowledgeGraph(df)\n",
        "\n",
        "    return kg.split_kg(sizes=(len(df1), len(df2), len(df3)))\n"
      ],
      "metadata": {
        "id": "Rx1hLclp5Vx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg_train_path = \"/content/drive/MyDrive/Colab Notebooks/KG_breast_cancer/DATA/kg_train_pickle\"\n",
        "kg_test_path = \"/content/drive/MyDrive/Colab Notebooks/KG_breast_cancer/DATA/kg_test_pickle\"\n",
        "kg_val_path = \"/content/drive/MyDrive/Colab Notebooks/KG_breast_cancer/DATA/kg_val_pickle\""
      ],
      "metadata": {
        "id": "V-56P49OTaNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "file = open(kg_train_path, 'rb')\n",
        "train_data = pickle.load(file)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "9yaokaBjoAIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(kg_test_path, 'rb')\n",
        "test_data = pickle.load(file)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "hHfX6y6nUklL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(kg_val_path, 'rb')\n",
        "val_data = pickle.load(file)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "kjwL-KdtUoST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "kg_train, kg_val, kg_test = load_biodata()"
      ],
      "metadata": {
        "id": "qez_ksbouFcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainLoop():\n",
        "    def __init__(self, args , kg_train, kg_val, kg_test):\n",
        "        self.n_epochs = args.n_epochs\n",
        "        self.kg_train, self.kg_val, self.kg_test = kg_train, kg_val, kg_test\n",
        "        self.train_dataloader = DataLoader(kg_train, batch_size=args.b_size, use_cuda='all')\n",
        "        self.val_dataloader = DataLoader(kg_val, batch_size=args.b_size, use_cuda='all')\n",
        "        self.test_dataloader = DataLoader(kg_test, batch_size=args.b_size, use_cuda='all')\n",
        "        self.model_path = args.model_path\n",
        "        self.model = TransEModel(args.emb_dim, kg_train.n_ent, kg_train.n_rel, dissimilarity_type='L2')\n",
        "        self.criterion = MarginLoss(args.margin)\n",
        "        # Move everything to CUDA if available\n",
        "        if cuda.is_available():\n",
        "            cuda.empty_cache()\n",
        "            self.model.cuda()\n",
        "            self.criterion.cuda()\n",
        "\n",
        "        # Define the torch optimizer to be used\n",
        "        self.optimizer = Adam(self.model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
        "\n",
        "        self.sampler = BernoulliNegativeSampler(self.kg_train)\n",
        "\n",
        "    def fit_step(self):\n",
        "        running_loss = 0.0\n",
        "        for i, batch in enumerate(self.train_dataloader):\n",
        "            h, t, r = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "            n_h, n_t = self.sampler.corrupt_batch(h.to('cpu'), t.to('cpu'), r.to('cpu'))\n",
        "            n_h, n_t = n_h.to(device), n_t.to(device)\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            pos, neg = self.model(h, t, r, n_h, n_t)\n",
        "            loss = self.criterion(pos, neg)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        return running_loss\n",
        "    def test_step(self):\n",
        "        self.model = torch.load(self.model_path)\n",
        "        self.model.eval()\n",
        "        evaluator = LinkPredictionEvaluator(self.model, self.kg_test)\n",
        "        evaluator.evaluate(200, verbose=True)\n",
        "        evaluator.print_results()\n",
        "\n",
        "    def eval_step(self):\n",
        "        evaluator = LinkPredictionEvaluator(self.model, self.kg_val)\n",
        "        evaluator.evaluate(200, verbose=False)\n",
        "        return evaluator.mrr()[1]\n",
        "\n",
        "    def fit(self):\n",
        "        iterator = tqdm(range(self.n_epochs), unit='epoch')\n",
        "        best_val = -np.inf\n",
        "        patience= 10\n",
        "        patience_count = 0\n",
        "        for epoch in iterator:\n",
        "            running_loss = self.fit_step()\n",
        "            val_ = self.eval_step()\n",
        "\n",
        "            if val_> best_val:\n",
        "                best_val = val_\n",
        "                torch.save(self.model, self.model_path)\n",
        "                patience_count = 0\n",
        "            else:\n",
        "                if patience_count == patience:\n",
        "                    break\n",
        "                else:\n",
        "                    patience_count += 1\n",
        "\n",
        "            iterator.set_description(\n",
        "                'Epoch {} | mean loss: {:.5f}'.format(epoch + 1,\n",
        "                                                      running_loss / len(self.train_dataloader)))\n",
        "\n",
        "        self.model.normalize_parameters()"
      ],
      "metadata": {
        "id": "31lvZ25ttXOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Params():\n",
        "    def __init__(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "cbhAR99GzAcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Params()"
      ],
      "metadata": {
        "id": "9rBQ-lsUy80h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.emb_dim = 100\n",
        "args.lr = 0.0004\n",
        "args.n_epochs = 1000\n",
        "args.b_size = 32768\n",
        "args.margin = 0.5\n",
        "args.model_path = join(MODEL_PATH, \"basic.bt\")"
      ],
      "metadata": {
        "id": "wnzL4x3BzKdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tloop = TrainLoop(args, kg_train, kg_val, kg_test)"
      ],
      "metadata": {
        "id": "Ah_LuvIvy6_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tloop.fit()"
      ],
      "metadata": {
        "id": "_lcx2uLR0tEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tloop.test_step()"
      ],
      "metadata": {
        "id": "LhQgeBqm0aS8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}